{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221d086b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Google Generative AI Integration\n",
    "\n",
    "This notebook demonstrates how to use Google's free generative AI models (Gemini) via two approaches:\n",
    "1. Using the LangChain framework\n",
    "2. Using the Google Generative AI API directly\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Package Installation\n",
    "Install the required packages using pip:\n",
    "```bash\n",
    "pip install python-dotenv langchain langchain-google-genai google-genai\n",
    "```\n",
    "\n",
    "### API Key Setup\n",
    "1. Get a Google API key from: https://aistudio.google.com/apikey\n",
    "2. Create a `.env` file in the same directory as this notebook with the following content:\n",
    "```\n",
    "GOOGLE_API_KEY="your_api_key_here"\n",
    "```\n",
    "Replace `your_api_key_here` with the actual API key you obtained from Google AI Studio.\n",
    "\n",
    "## Setup\n",
    "The cell below sets up the environment variables, loading the Google API key from a .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e0b84",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## LangChain Integration - Text Generation\n",
    "\n",
    "This cell demonstrates how to use the Gemini-2.5-Flash model through the LangChain framework for text generation. \n",
    "The code initializes a chat model using LangChain's interface and sends a simple query.\n",
    "\n",
    "see the documentation for more info: https://python.langchain.com/docs/how_to/chat_models_universal_init/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    model_provider=\"google_genai\",\n",
    "    google_api_key=GOOGLE_API_KEY,\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"in one sentence - What is the meaning of life?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2184b8bb",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## LangChain Integration - Embeddings\n",
    "\n",
    "This cell shows how to generate embeddings using Google's embedding model through LangChain. \n",
    "Embeddings are vector representations of text that capture semantic meaning, useful for RAG applications and similarity searches.\n",
    "\n",
    "see the documentation for more info: https://python.langchain.com/docs/integrations/text_embedding/google_generative_ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb99f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
    "\n",
    "result = embeddings.embed_query(\"What is the meaning of life?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38d0c1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Direct Google Generative AI API - Text Generation\n",
    "\n",
    "This cell demonstrates how to use the Google Generative AI API directly (without LangChain).\n",
    "It initializes a client and creates a chat session using the Gemini-2.5-Flash model to generate a response to the same query.\n",
    "\n",
    "see the documentation for more info: https://ai.google.dev/gemini-api/docs/text-generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81193fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "llm = client.chats.create(model=\"gemini-2.5-flash\")\n",
    "\n",
    "response = llm.send_message(\"in one sentence - What is the meaning of life?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c719740",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Direct Google Generative AI API - Embeddings\n",
    "\n",
    "This cell shows how to generate embeddings directly using the Google Generative AI API (without LangChain).\n",
    "\n",
    "see the documentation for more info: https://ai.google.dev/gemini-api/docs/embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8254e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "result = client.models.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        contents=\"What is the meaning of life?\")\n",
    "\n",
    "print(result.embeddings[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
